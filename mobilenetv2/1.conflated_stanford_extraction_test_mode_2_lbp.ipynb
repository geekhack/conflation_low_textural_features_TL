{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.13.3; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.13.3; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencv-python-headless) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-image in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
      "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.5.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (8.1.0)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as mobilenetv2\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from keras import layers, Sequential\n",
    "from matplotlib import pyplot\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import expand_dims, array, exp, max\n",
    "import json\n",
    "import skimage.feature as feature\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import local_binary_pattern\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 38, 38, 32)        0         \n",
      "=================================================================\n",
      "Total params: 864\n",
      "Trainable params: 864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = mobilenetv2()\n",
    "model2 = Model(inputs=model1.inputs, outputs=model1.layers[1].output)\n",
    "# model.add(layers.MaxPool2D(pool_size=(2, 2),strides=(1, 1), padding='valid'))\n",
    "model = Sequential(layers=model2.layers)\n",
    "model.add(layers.MaxPool2D(pool_size=(3, 3), strides=(3, 3), padding='same'))\n",
    "# model = Model(inputs=model.inputs, outputs = model.layers[1].output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "  def __init__(self, numPoints, radius):\n",
    "    self.numPoints = numPoints\n",
    "    self.radius = radius\n",
    "\n",
    "  def describe(self, image, eps = 1e-7):\n",
    "    lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints+3), range=(0, self.numPoints + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + eps)\n",
    "\n",
    "    return hist, lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02113978_3391.jpg', 'n02113978_1535.jpg', 'n02113978_3504.jpg', 'n02113978_2276.jpg', 'n02113978_2727.jpg', 'n02113978_2979.jpg', 'n02113978_3349.jpg', 'n02113978_2141.jpg', 'n02113978_2677.jpg', 'n02113978_2446.jpg', 'n02113978_3823.jpg', 'n02113978_2546.jpg', 'n02113978_1999.jpg', 'n02113978_1854.jpg', 'n02113978_3197.jpg', 'n02113978_3714.jpg', 'n02113978_2261.jpg', 'n02113978_1030.jpg', 'n02113978_1595.jpg', 'n02113978_2167.jpg', 'n02113978_1238.jpg', 'n02113978_3056.jpg', 'n02113978_1391.jpg', 'n02113978_2128.jpg', 'n02113978_1957.jpg', 'n02113978_3375.jpg', 'n02113978_3734.jpg', 'n02113978_2425.jpg', 'n02113978_1954.jpg', 'n02113978_1823.jpg', 'n02113978_1620.jpg', 'n02113978_2804.jpg', 'n02113978_2143.jpg', 'n02113978_1867.jpg', 'n02113978_3220.jpg', 'n02113978_2709.jpg', 'n02113978_1970.jpg', 'n02113978_3134.jpg', 'n02113978_153.jpg', 'n02113978_3184.jpg', 'n02113978_605.jpg', 'n02113978_3655.jpg', 'n02113978_3474.jpg', 'n02113978_2306.jpg', 'n02113978_3249.jpg', 'n02113978_3727.jpg', 'n02113978_2787.jpg', 'n02113978_356.jpg', 'n02113978_505.jpg', 'n02113978_1653.jpg', 'n02113978_553.jpg', 'n02113978_2572.jpg', 'n02113978_3921.jpg', 'n02113978_3480.jpg', 'n02113978_1632.jpg', 'n02113978_573.jpg', 'n02113978_3419.jpg', 'n02113978_697.jpg', 'n02113978_2695.jpg', 'n02113978_3743.jpg', 'n02113978_773.jpg', 'n02113978_857.jpg', 'n02113978_937.jpg', 'n02113978_2552.jpg', 'n02113978_903.jpg', 'n02113978_3723.jpg', 'n02113978_2474.jpg', 'n02113978_471.jpg', 'n02113978_1006.jpg', 'n02113978_870.jpg', 'n02113978_272.jpg', 'n02113978_1773.jpg', 'n02113978_386.jpg', 'n02113978_2337.jpg', 'n02113978_1787.jpg', 'n02113978_1482.jpg', 'n02113978_1349.jpg', 'n02113978_3746.jpg', 'n02113978_3794.jpg', 'n02113978_530.jpg', 'n02113978_3092.jpg', 'n02113978_3804.jpg', 'n02113978_2888.jpg', 'n02113978_3318.jpg', 'n02113978_1983.jpg', 'n02113978_838.jpg', 'n02113978_2938.jpg', 'n02113978_183.jpg', 'n02113978_131.jpg', 'n02113978_2145.jpg', 'n02113978_1551.jpg', 'n02113978_1317.jpg', 'n02113978_118.jpg', 'n02113978_3822.jpg', 'n02113978_2606.jpg', 'n02113978_1189.jpg', 'n02113978_3640.jpg', 'n02113978_341.jpg', 'n02113978_2441.jpg', 'n02113978_124.jpg', 'n02113978_2793.jpg', 'n02113978_3722.jpg', 'n02113978_2121.jpg', 'n02113978_2508.jpg', 'n02113978_1480.jpg', 'n02113978_2003.jpg', 'n02113978_1956.jpg', 'n02113978_961.jpg', 'n02113978_310.jpg', 'n02113978_1478.jpg', 'n02113978_632.jpg', 'n02113978_468.jpg', 'n02113978_2798.jpg', 'n02113978_3864.jpg', 'n02113978_1994.jpg', 'n02113978_737.jpg', 'n02113978_3670.jpg', 'n02113978_1868.jpg', 'n02113978_839.jpg', 'n02113978_216.jpg', 'n02113978_3101.jpg', 'n02113978_3071.jpg', 'n02113978_3790.jpg', 'n02113978_304.jpg', 'n02113978_375.jpg', 'n02113978_2189.jpg', 'n02113978_2073.jpg', 'n02113978_1325.jpg', 'n02113978_143.jpg', 'n02113978_1891.jpg', 'n02113978_1034.jpg', 'n02113978_3843.jpg', 'n02113978_177.jpg', 'n02113978_593.jpg', 'n02113978_2966.jpg', 'n02113978_2726.jpg', 'n02113978_2054.jpg', 'n02113978_3832.jpg', 'n02113978_1088.jpg', 'n02113978_996.jpg', 'n02113978_2996.jpg', 'n02113978_1924.jpg', 'n02113978_3866.jpg', 'n02113978_451.jpg', 'n02113978_700.jpg', 'n02113978_1939.jpg', 'n02113978_1746.jpg', 'n02113978_147.jpg', 'n02113978_206.jpg', 'n02113978_2286.jpg', 'n02113978_1069.jpg', 'n02113978_759.jpg', 'n02113978_2707.jpg', 'n02113978_1323.jpg', 'n02113978_3178.jpg']\n"
     ]
    }
   ],
   "source": [
    "###########################THIS CODE CHECKS IMAGES FROM A FOLDER#################################\n",
    "\n",
    "def sortTrainImages():\n",
    "    # get the class labels from training datasets\n",
    "    p = {}\n",
    "    data_path = '../../StanfordDogs/Stanford_Dogs'\n",
    "    img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255, rotation_range=20)\n",
    "    #labels = img_gen.flow_from_directory(data_path + '/Images')\n",
    "    #train_labels = labels.class_indices.keys()\n",
    "\n",
    "    #for lbl in train_labels:\n",
    "    resnet_path = data_path +'/Images/' + 'n02113978-Mexican_hairless'\n",
    "    p_files = [f for f in listdir(resnet_path) if isfile(join(resnet_path, f))]\n",
    "    pests_images = np.empty(len(p_files), dtype=object)\n",
    "    print(p_files)\n",
    "    for m in range(0, len(p_files)):\n",
    "        \n",
    "            #print(join(resnet_path, p_files[m]))\n",
    "        imageName_x = p_files[m]\n",
    "        p.update({'n02113978-Mexican_hairless' + \"_\" + str(m): imageName_x})\n",
    "            ######if m < 25:\n",
    "                #pests_images[m] = cv2.imread(join(resnet_path, p_files[m]))\n",
    "                # get the name of the image\n",
    "                ######imageName_x = p_files[m]\n",
    "                #####p.update({lbl + \"_\" + str(m): imageName_x})\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "images_collection = sortTrainImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMax(temperature, features_list):\n",
    "    feat_list = [x / temperature for x in features_list]\n",
    "    feature_list = exp(feat_list - max(feat_list))\n",
    "    return feature_list / feature_list.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing scikit learn lbp implementation\n",
    "# type of LBP\n",
    "METHOD = 'uniform'  # at most two circular 0-1 or 1-0 transitions\n",
    "radius = 1  # distance between central pixels and comparison pixels\n",
    "n_points = 8 * radius  # define number of comparison pixels\n",
    "\n",
    "#all features\n",
    "all_features= []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "#second method\n",
    "for o, j in images_collection.items():\n",
    "    # create list for LBP representations\n",
    "    lbp_imgs = []\n",
    "    \n",
    "    image_string = '../../StanfordDogs/Stanford_Dogs/Images/n02113978-Mexican_hairless/' + j\n",
    "  \n",
    "    img = imread(image_string)\n",
    "    img = resize(img,(224,224,3))\n",
    "        # get the path of image to extract the class\n",
    "    img_class =j[0]\n",
    "    img = img_to_array(img)    \n",
    "    # expand the image dimensions\n",
    "    img = expand_dims(img, axis=0)\n",
    "        # scale the pixels\n",
    "    img = preprocess_input(img)\n",
    "        # get the features of the first layer\n",
    "    feature_maps = model.predict(img)\n",
    "   \n",
    "    ix = 1\n",
    "    square = 3\n",
    "    features_prob_dist_array = []\n",
    "    \n",
    "    \n",
    "    for _ in range(square):     \n",
    "        \n",
    "        each_main_feature = []\n",
    "        \n",
    "        for _ in range(square):\n",
    "            ax = pyplot.subplot(square, square, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ##################FLATTEN THE FEATURE for dimensionality reduction##################################\n",
    "            feature_items = array(feature_maps[0, :, :, ix - 1])\n",
    "            #get the unsigned values of the feature\n",
    "            features_x = feature_items.astype(np.uint8)\n",
    "            lbp = local_binary_pattern(features_x, n_points, radius, METHOD)\n",
    "            \n",
    "            each_feature = []\n",
    "            \n",
    "            for h in lbp:\n",
    "                #get the top 5 important features\n",
    "                n_array = np.array(h)\n",
    "                #each_sub_feature = np.prod(h, axis = 0, where = h > 0, keepdims = True)\n",
    "                n_array= np.sort(n_array)\n",
    "                each_soft = softMax(0.5,n_array[-8:])\n",
    "                prod_sub_items = np.prod(each_soft)\n",
    "                each_feature.append(prod_sub_items)\n",
    "            numerator = each_feature\n",
    "            denominator = np.trapz(numerator,axis=0)\n",
    "            conf_list =(numerator/denominator)\n",
    "            \n",
    "            #final_array = softMax(0.5,features_prob_dist_array), the list is based on the softmax prob\n",
    "            final_array_numerator=  (softMax(0.5,conf_list))\n",
    "            final_array_denominator = np.trapz(final_array_numerator,axis=0)\n",
    "            \n",
    "            \n",
    "            final_array_conf_list = final_array_numerator/final_array_denominator\n",
    "            \n",
    "            each_item_x = np.prod(final_array_conf_list)\n",
    "            \n",
    "            each_main_feature.append(each_item_x)\n",
    "        \n",
    "            #final_array_numerator=str(final_array_numerator)\n",
    "            #first_chars = float(final_array_numerator[0:8])\n",
    "            #print(first_chars)\n",
    "            \n",
    "            ix += 1\n",
    "        #print(each_main_feature)   \n",
    "        #get the conflation of all the features of the specific image\n",
    "        \n",
    "    #print(type(each_main_feature))\n",
    "    \n",
    "    new_rec = {j + \"_/\" +'n02113978-Mexican_hairless': each_main_feature}\n",
    "    \n",
    "    with open(\"../../files/mobilenetv2/lbp/stanford_target_domain_lbp.json\", 'r+') as file:\n",
    "            # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"target_images\"].append(new_rec)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent=4)\n",
    "    print(\"*\")\n",
    "       \n",
    "    \n",
    "       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
